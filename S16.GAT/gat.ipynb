{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIB1fKwTK_q2"
      },
      "source": [
        "# Graph Attention Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k9aRrEKK_q9"
      },
      "source": [
        "**WARNING**<br>\n",
        "Execute only the colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qz6mZSmTK_rA",
        "outputId": "86f52323-d816-4ce0-bc26-6279324bfdb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
            "Collecting pyg-lib\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/pyg_lib-0.2.0%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_scatter-2.1.1%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (9.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-1.13.0%2Bcu116/torch_sparse-0.6.17%2Bpt113cu116-cp39-cp39-linux_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-sparse) (1.10.1)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.9/dist-packages (from scipy->torch-sparse) (1.22.4)\n",
            "Installing collected packages: torch-scatter, pyg-lib, torch-sparse\n",
            "Successfully installed pyg-lib-0.2.0+pt113cu116 torch-scatter-2.1.1+pt113cu116 torch-sparse-0.6.17+pt113cu116\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.3.0.tar.gz (616 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.2/616.2 KB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.1.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (5.9.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (4.65.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.10.1)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (3.0.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torch-geometric) (1.22.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch-geometric) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torch-geometric) (2022.12.7)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->torch-geometric) (1.1.1)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.3.0-py3-none-any.whl size=909897 sha256=a5e795025c05e6fea884e051b529e4df92e5a140c4e9670068cc9c2d58cf95cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/cd/7d/6b/17150450b80b4a3656a84330e22709ccd8dc0f8f4773ba4133\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.3.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.8.0\n",
            "  Downloading scipy-1.8.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<1.25.0,>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scipy==1.8.0) (1.22.4)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "Successfully installed scipy-1.8.0\n"
          ]
        }
      ],
      "source": [
        "# install torch-geometric and related libraries\n",
        "!pip install pyg-lib torch-scatter torch-sparse -f https://data.pyg.org/whl/torch-1.13.0+cu116.html\n",
        "!pip install torch-geometric\n",
        "!pip install scipy==1.8.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0DexeZIK_rC"
      },
      "source": [
        "## Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kYCJrb7LK_rD",
        "outputId": "8506bdf0-807e-41c9-f518-150d1272be9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
            "Extracting data/TUDataset/MUTAG/MUTAG.zip\n",
            "Processing...\n",
            "Done!\n",
            "/usr/local/lib/python3.9/dist-packages/torch_geometric/deprecation.py:22: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
            "  warnings.warn(out)\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.datasets import TUDataset\n",
        "from torch_geometric.data import DataLoader\n",
        "\n",
        "# load dataset\n",
        "dataset = TUDataset(root='data/TUDataset', name='MUTAG')\n",
        "\n",
        "# split dataset into train, validation and test\n",
        "dataset = dataset.shuffle()\n",
        "train_dataset = dataset[:140]\n",
        "val_dataset = dataset[140:]\n",
        "\n",
        "# create dataloader\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sthO235fK_rE"
      },
      "source": [
        "## Build the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2BIxTbC-K_rF",
        "outputId": "76ffbd9b-e5b2-474b-895c-1d764dc963ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GAT(\n",
              "  (gat1): GATConv(7, 64, heads=32)\n",
              "  (gat2): GATConv(2048, 64, heads=32)\n",
              "  (fc1): Linear(in_features=2048, out_features=2, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (dropout): Dropout(p=0.5, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# define model\n",
        "# import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch_geometric.nn import GATConv, global_mean_pool\n",
        "\n",
        "# set parameters\n",
        "n_features = dataset.num_features\n",
        "n_hidden = 64\n",
        "n_heads = 32\n",
        "n_classes = dataset.num_classes\n",
        "\n",
        "# define model class\n",
        "class GAT(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(GAT, self).__init__()\n",
        "        self.gat1 = GATConv(n_features, n_hidden, heads=n_heads)\n",
        "        self.gat2 = GATConv(n_hidden * n_heads, n_hidden, heads=n_heads)\n",
        "        self.fc1 = nn.Linear(n_hidden * n_heads, n_classes)\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        batch = data.batch\n",
        "\n",
        "        x = self.gat1(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = self.gat2(x, edge_index)\n",
        "        x = self.relu(x)\n",
        "        x = global_mean_pool(x, batch)\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc1(x)\n",
        "\n",
        "        return x\n",
        "    \n",
        "net = GAT()\n",
        "net.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVP_Z-XZK_rG"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NXJsuQ6LK_rH",
        "outputId": "fc736992-6696-4bdc-eecf-3bfa476425e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 2/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 3/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 4/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 5/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 6/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 7/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 8/200, Train Acc: 67.14%, Val Acc: 64.58%\n",
            "Epoch 9/200, Train Acc: 67.14%, Val Acc: 66.67%\n",
            "Epoch 10/200, Train Acc: 67.86%, Val Acc: 66.67%\n",
            "Epoch 11/200, Train Acc: 72.14%, Val Acc: 68.75%\n",
            "Epoch 12/200, Train Acc: 75.71%, Val Acc: 68.75%\n",
            "Epoch 13/200, Train Acc: 72.14%, Val Acc: 79.17%\n",
            "Epoch 14/200, Train Acc: 72.14%, Val Acc: 79.17%\n",
            "Epoch 15/200, Train Acc: 76.43%, Val Acc: 77.08%\n",
            "Epoch 16/200, Train Acc: 75.00%, Val Acc: 75.00%\n",
            "Epoch 17/200, Train Acc: 72.14%, Val Acc: 77.08%\n",
            "Epoch 18/200, Train Acc: 75.71%, Val Acc: 77.08%\n",
            "Epoch 19/200, Train Acc: 75.71%, Val Acc: 75.00%\n",
            "Epoch 20/200, Train Acc: 75.00%, Val Acc: 75.00%\n",
            "Epoch 21/200, Train Acc: 76.43%, Val Acc: 77.08%\n",
            "Epoch 22/200, Train Acc: 75.71%, Val Acc: 77.08%\n",
            "Epoch 23/200, Train Acc: 75.71%, Val Acc: 77.08%\n",
            "Epoch 24/200, Train Acc: 76.43%, Val Acc: 70.83%\n",
            "Epoch 25/200, Train Acc: 76.43%, Val Acc: 70.83%\n",
            "Epoch 26/200, Train Acc: 75.00%, Val Acc: 79.17%\n",
            "Epoch 27/200, Train Acc: 75.00%, Val Acc: 79.17%\n",
            "Epoch 28/200, Train Acc: 77.14%, Val Acc: 72.92%\n",
            "Epoch 29/200, Train Acc: 77.14%, Val Acc: 70.83%\n",
            "Epoch 30/200, Train Acc: 75.71%, Val Acc: 79.17%\n",
            "Epoch 31/200, Train Acc: 76.43%, Val Acc: 77.08%\n",
            "Epoch 32/200, Train Acc: 77.14%, Val Acc: 79.17%\n",
            "Epoch 33/200, Train Acc: 77.14%, Val Acc: 75.00%\n",
            "Epoch 34/200, Train Acc: 77.86%, Val Acc: 72.92%\n",
            "Epoch 35/200, Train Acc: 77.14%, Val Acc: 75.00%\n",
            "Epoch 36/200, Train Acc: 76.43%, Val Acc: 79.17%\n",
            "Epoch 37/200, Train Acc: 77.14%, Val Acc: 79.17%\n",
            "Epoch 38/200, Train Acc: 75.71%, Val Acc: 79.17%\n",
            "Epoch 39/200, Train Acc: 78.57%, Val Acc: 72.92%\n",
            "Epoch 40/200, Train Acc: 78.57%, Val Acc: 72.92%\n",
            "Epoch 41/200, Train Acc: 78.57%, Val Acc: 75.00%\n",
            "Epoch 42/200, Train Acc: 76.43%, Val Acc: 79.17%\n",
            "Epoch 43/200, Train Acc: 77.86%, Val Acc: 77.08%\n",
            "Epoch 44/200, Train Acc: 75.71%, Val Acc: 79.17%\n",
            "Epoch 45/200, Train Acc: 80.00%, Val Acc: 79.17%\n",
            "Epoch 46/200, Train Acc: 77.14%, Val Acc: 79.17%\n",
            "Epoch 47/200, Train Acc: 77.86%, Val Acc: 79.17%\n",
            "Epoch 48/200, Train Acc: 77.86%, Val Acc: 79.17%\n",
            "Epoch 49/200, Train Acc: 79.29%, Val Acc: 75.00%\n",
            "Epoch 50/200, Train Acc: 78.57%, Val Acc: 79.17%\n",
            "Epoch 51/200, Train Acc: 77.86%, Val Acc: 79.17%\n",
            "Epoch 52/200, Train Acc: 79.29%, Val Acc: 79.17%\n",
            "Epoch 53/200, Train Acc: 80.00%, Val Acc: 75.00%\n",
            "Epoch 54/200, Train Acc: 80.71%, Val Acc: 77.08%\n",
            "Epoch 55/200, Train Acc: 81.43%, Val Acc: 77.08%\n",
            "Epoch 56/200, Train Acc: 80.71%, Val Acc: 75.00%\n",
            "Epoch 57/200, Train Acc: 79.29%, Val Acc: 77.08%\n",
            "Epoch 58/200, Train Acc: 79.29%, Val Acc: 77.08%\n",
            "Epoch 59/200, Train Acc: 78.57%, Val Acc: 77.08%\n",
            "Epoch 60/200, Train Acc: 77.86%, Val Acc: 75.00%\n",
            "Epoch 61/200, Train Acc: 78.57%, Val Acc: 75.00%\n",
            "Epoch 62/200, Train Acc: 80.71%, Val Acc: 70.83%\n",
            "Epoch 63/200, Train Acc: 81.43%, Val Acc: 70.83%\n",
            "Epoch 64/200, Train Acc: 78.57%, Val Acc: 72.92%\n",
            "Epoch 65/200, Train Acc: 79.29%, Val Acc: 77.08%\n",
            "Epoch 66/200, Train Acc: 80.71%, Val Acc: 77.08%\n",
            "Epoch 67/200, Train Acc: 82.14%, Val Acc: 72.92%\n",
            "Epoch 68/200, Train Acc: 82.14%, Val Acc: 77.08%\n",
            "Epoch 69/200, Train Acc: 80.00%, Val Acc: 72.92%\n",
            "Epoch 70/200, Train Acc: 82.14%, Val Acc: 75.00%\n",
            "Epoch 71/200, Train Acc: 81.43%, Val Acc: 75.00%\n",
            "Epoch 72/200, Train Acc: 81.43%, Val Acc: 77.08%\n",
            "Epoch 73/200, Train Acc: 82.86%, Val Acc: 70.83%\n",
            "Epoch 74/200, Train Acc: 82.14%, Val Acc: 75.00%\n",
            "Epoch 75/200, Train Acc: 79.29%, Val Acc: 72.92%\n",
            "Epoch 76/200, Train Acc: 79.29%, Val Acc: 72.92%\n",
            "Epoch 77/200, Train Acc: 82.86%, Val Acc: 77.08%\n",
            "Epoch 78/200, Train Acc: 86.43%, Val Acc: 72.92%\n",
            "Epoch 79/200, Train Acc: 85.71%, Val Acc: 70.83%\n",
            "Epoch 80/200, Train Acc: 78.57%, Val Acc: 75.00%\n",
            "Epoch 81/200, Train Acc: 77.86%, Val Acc: 72.92%\n",
            "Epoch 82/200, Train Acc: 79.29%, Val Acc: 75.00%\n",
            "Epoch 83/200, Train Acc: 80.71%, Val Acc: 77.08%\n",
            "Epoch 84/200, Train Acc: 80.71%, Val Acc: 77.08%\n",
            "Epoch 85/200, Train Acc: 80.00%, Val Acc: 77.08%\n",
            "Epoch 86/200, Train Acc: 80.00%, Val Acc: 77.08%\n",
            "Epoch 87/200, Train Acc: 81.43%, Val Acc: 79.17%\n",
            "Epoch 88/200, Train Acc: 81.43%, Val Acc: 77.08%\n",
            "Epoch 89/200, Train Acc: 82.86%, Val Acc: 79.17%\n",
            "Epoch 90/200, Train Acc: 82.86%, Val Acc: 79.17%\n",
            "Epoch 91/200, Train Acc: 80.00%, Val Acc: 77.08%\n",
            "Epoch 92/200, Train Acc: 80.71%, Val Acc: 77.08%\n",
            "Epoch 93/200, Train Acc: 82.86%, Val Acc: 79.17%\n",
            "Epoch 94/200, Train Acc: 83.57%, Val Acc: 79.17%\n",
            "Epoch 95/200, Train Acc: 83.57%, Val Acc: 79.17%\n",
            "Epoch 96/200, Train Acc: 83.57%, Val Acc: 77.08%\n",
            "Epoch 97/200, Train Acc: 84.29%, Val Acc: 79.17%\n",
            "Epoch 98/200, Train Acc: 83.57%, Val Acc: 77.08%\n",
            "Epoch 99/200, Train Acc: 82.86%, Val Acc: 77.08%\n",
            "Epoch 100/200, Train Acc: 84.29%, Val Acc: 79.17%\n",
            "Epoch 101/200, Train Acc: 82.86%, Val Acc: 72.92%\n",
            "Epoch 102/200, Train Acc: 87.14%, Val Acc: 72.92%\n",
            "Epoch 103/200, Train Acc: 87.86%, Val Acc: 75.00%\n",
            "Epoch 104/200, Train Acc: 81.43%, Val Acc: 77.08%\n",
            "Epoch 105/200, Train Acc: 80.71%, Val Acc: 75.00%\n",
            "Epoch 106/200, Train Acc: 81.43%, Val Acc: 77.08%\n",
            "Epoch 107/200, Train Acc: 82.14%, Val Acc: 79.17%\n",
            "Epoch 108/200, Train Acc: 82.86%, Val Acc: 75.00%\n",
            "Epoch 109/200, Train Acc: 82.14%, Val Acc: 77.08%\n",
            "Epoch 110/200, Train Acc: 81.43%, Val Acc: 77.08%\n",
            "Epoch 111/200, Train Acc: 82.86%, Val Acc: 77.08%\n",
            "Epoch 112/200, Train Acc: 82.86%, Val Acc: 79.17%\n",
            "Epoch 113/200, Train Acc: 86.43%, Val Acc: 75.00%\n",
            "Epoch 114/200, Train Acc: 83.57%, Val Acc: 79.17%\n",
            "Epoch 115/200, Train Acc: 82.86%, Val Acc: 79.17%\n",
            "Epoch 116/200, Train Acc: 85.71%, Val Acc: 75.00%\n",
            "Epoch 117/200, Train Acc: 86.43%, Val Acc: 75.00%\n",
            "Epoch 118/200, Train Acc: 81.43%, Val Acc: 79.17%\n",
            "Epoch 119/200, Train Acc: 81.43%, Val Acc: 79.17%\n",
            "Epoch 120/200, Train Acc: 86.43%, Val Acc: 75.00%\n",
            "Epoch 121/200, Train Acc: 87.14%, Val Acc: 72.92%\n",
            "Epoch 122/200, Train Acc: 85.00%, Val Acc: 75.00%\n",
            "Epoch 123/200, Train Acc: 81.43%, Val Acc: 79.17%\n",
            "Epoch 124/200, Train Acc: 82.86%, Val Acc: 79.17%\n",
            "Epoch 125/200, Train Acc: 82.86%, Val Acc: 81.25%\n",
            "Epoch 126/200, Train Acc: 87.14%, Val Acc: 72.92%\n",
            "Epoch 127/200, Train Acc: 84.29%, Val Acc: 72.92%\n",
            "Epoch 128/200, Train Acc: 84.29%, Val Acc: 72.92%\n",
            "Epoch 129/200, Train Acc: 84.29%, Val Acc: 72.92%\n",
            "Epoch 130/200, Train Acc: 84.29%, Val Acc: 75.00%\n",
            "Epoch 131/200, Train Acc: 86.43%, Val Acc: 72.92%\n",
            "Epoch 132/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 133/200, Train Acc: 87.14%, Val Acc: 72.92%\n",
            "Epoch 134/200, Train Acc: 85.71%, Val Acc: 72.92%\n",
            "Epoch 135/200, Train Acc: 85.71%, Val Acc: 75.00%\n",
            "Epoch 136/200, Train Acc: 85.71%, Val Acc: 77.08%\n",
            "Epoch 137/200, Train Acc: 86.43%, Val Acc: 72.92%\n",
            "Epoch 138/200, Train Acc: 87.14%, Val Acc: 72.92%\n",
            "Epoch 139/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 140/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 141/200, Train Acc: 88.57%, Val Acc: 72.92%\n",
            "Epoch 142/200, Train Acc: 87.86%, Val Acc: 72.92%\n",
            "Epoch 143/200, Train Acc: 85.71%, Val Acc: 72.92%\n",
            "Epoch 144/200, Train Acc: 85.71%, Val Acc: 77.08%\n",
            "Epoch 145/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 146/200, Train Acc: 85.71%, Val Acc: 72.92%\n",
            "Epoch 147/200, Train Acc: 85.71%, Val Acc: 72.92%\n",
            "Epoch 148/200, Train Acc: 87.86%, Val Acc: 75.00%\n",
            "Epoch 149/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 150/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 151/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 152/200, Train Acc: 86.43%, Val Acc: 72.92%\n",
            "Epoch 153/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 154/200, Train Acc: 88.57%, Val Acc: 77.08%\n",
            "Epoch 155/200, Train Acc: 82.86%, Val Acc: 83.33%\n",
            "Epoch 156/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 157/200, Train Acc: 87.86%, Val Acc: 72.92%\n",
            "Epoch 158/200, Train Acc: 85.71%, Val Acc: 75.00%\n",
            "Epoch 159/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 160/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 161/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 162/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 163/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 164/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 165/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 166/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 167/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 168/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 169/200, Train Acc: 87.86%, Val Acc: 75.00%\n",
            "Epoch 170/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 171/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 172/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 173/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 174/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 175/200, Train Acc: 88.57%, Val Acc: 77.08%\n",
            "Epoch 176/200, Train Acc: 87.86%, Val Acc: 77.08%\n",
            "Epoch 177/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 178/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 179/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 180/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 181/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 182/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 183/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 184/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 185/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 186/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 187/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 188/200, Train Acc: 87.14%, Val Acc: 77.08%\n",
            "Epoch 189/200, Train Acc: 86.43%, Val Acc: 77.08%\n",
            "Epoch 190/200, Train Acc: 86.43%, Val Acc: 72.92%\n",
            "Epoch 191/200, Train Acc: 86.43%, Val Acc: 75.00%\n",
            "Epoch 192/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 193/200, Train Acc: 86.43%, Val Acc: 72.92%\n",
            "Epoch 194/200, Train Acc: 86.43%, Val Acc: 70.83%\n",
            "Epoch 195/200, Train Acc: 87.86%, Val Acc: 70.83%\n",
            "Epoch 196/200, Train Acc: 88.57%, Val Acc: 75.00%\n",
            "Epoch 197/200, Train Acc: 88.57%, Val Acc: 77.08%\n",
            "Epoch 198/200, Train Acc: 87.14%, Val Acc: 75.00%\n",
            "Epoch 199/200, Train Acc: 86.43%, Val Acc: 75.00%\n",
            "Epoch 200/200, Train Acc: 86.43%, Val Acc: 75.00%\n"
          ]
        }
      ],
      "source": [
        "# define loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(net.parameters())\n",
        "\n",
        "# define function to evaluate model\n",
        "def evaluate(loader):\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for data in loader:\n",
        "        data = data.cuda()\n",
        "        outputs = net(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += data.y.size(0)\n",
        "        correct += (predicted == data.y).sum().item()\n",
        "    return correct / total * 100\n",
        "\n",
        "# train model\n",
        "n_epochs = 200\n",
        "for epoch in range(n_epochs):\n",
        "    for i, data in enumerate(train_loader):\n",
        "        data = data.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(data)\n",
        "        loss = criterion(outputs, data.y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    net.eval()\n",
        "    train_acc = evaluate(train_loader)\n",
        "    val_acc = evaluate(val_loader)\n",
        "    print(f'Epoch {epoch+1}/{n_epochs}, Train Acc: {train_acc:.2f}%, Val Acc: {val_acc:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ue3pxB-K_rI"
      },
      "source": [
        "## Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "VlqubSR0K_rI",
        "outputId": "660c4fc0-5107-4043-8e90-38c92906c376",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Acc: 75.00%\n"
          ]
        }
      ],
      "source": [
        "# evaluate model\n",
        "net.eval()\n",
        "test_acc = evaluate(val_loader)\n",
        "print(f'Test Acc: {test_acc:.2f}%')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ai-master",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "2512312fceb6e908b1c6087f9c29f0bb0c93a332146a69690954edd67c2954cb"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}